{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 深層学習特論レポート\n",
    "\n",
    "\"Association of genomic subtypes of lower-grade gliomas with shape features automatically\n",
    "extracted by a deep learning algorithm\"\n",
    "\n",
    "- 氏名：楠 湧夢\n",
    "- 学生番号：19676114\n",
    "- paper with codeの分類：Brain Tumor Segmentation \n",
    "- 論文URL：https://arxiv.org/pdf/1906.03720v1.pdf\n",
    "- GitHubのURL：https://github.com/mateuszbuda/brain-segmentation-pytorch\n",
    "- Deep Learning Libraryの枠組み：PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "脳 MRI における異常セグメンテーションのための事前学習された重みを用いた医用画像セグメンテーションのためのバッチ正規化を用いた U-Net\n",
    "\n",
    "![](https://pytorch.org/assets/images/unet_brain_mri.png)\n",
    "\n",
    "バッチ正規化と ReLU 活性化機能を有する２つの畳み込み層と、符号化部に１つの Max プーリング層、\n",
    "復号部に代わりにアップ畳み込み層を含む４レベルのブロックから構成されている。\n",
    "\n",
    "各ブロックの畳み込みフィルタの数は、３２個、６４個、１２８個、２５６個である。\n",
    "\n",
    "バットネック層には５１２個の畳み込みフィルタがある。\n",
    "\n",
    "符号化層からは、復号化部の対応する層へのスキップ接続が行われる。\n",
    "\n",
    "入力画像は、プレコントラストシーケンス、 FLAIR シーケンス、ポストコントラストシーケンスから\n",
    "それぞれ3チャンネルの脳 MRI スライスである。\n",
    "\n",
    "出力は、入力画像と同じサイズの異常領域の１チャンネル確率マップである。\n",
    "\n",
    "事前学習モデルの入力画像は、3つのチャンネルを持ち、256x256ピクセルにリサイズされ、体積あたりのZスコアが正規化されている必要があります。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "Downloading: \"https://github.com/mateuszbuda/brain-segmentation-pytorch/archive/master.zip\" to C:\\Users\\izumu/.cache\\torch\\hub\\master.zip\n",
      "Downloading: \"https://github.com/mateuszbuda/brain-segmentation-pytorch/releases/download/v1.0/unet-e012d006.pt\" to C:\\Users\\izumu/.cache\\torch\\hub\\checkpoints\\unet-e012d006.pt\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "    in_channels=3, out_channels=1, init_features=32, pretrained=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "サンプル画像をダウンロードして使ってみる\n",
    "\n",
    "![入力](TCGA_CS_4944.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Download an example image\n",
    "import urllib\n",
    "url, filename = (\"https://github.com/mateuszbuda/brain-segmentation-pytorch/raw/master/assets/TCGA_CS_4944.png\", \"TCGA_CS_4944.png\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "input_image = Image.open(filename)\n",
    "m, s = np.mean(input_image, axis=(0, 1)), np.std(input_image, axis=(0, 1))\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=m, std=s),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model = model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "print(torch.round(output[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "得られた出力を白黒画像として保存\n",
    "\n",
    "![出力](TCGA_CS_4944_inference.jpg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "L\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "im = torch.round(output[0]).clone().numpy()\n",
    "im = 255*im[0]\n",
    "print(im)\n",
    "\n",
    "pil_image_gray = Image.fromarray(im.astype(np.uint8))\n",
    "print(pil_image_gray.mode)\n",
    "pil_image_gray.save('TCGA_CS_4944_inference.jpg')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## モデルのサマリ\n",
    "\n",
    "３チャネル 256×256 画像を入力に指定することで `torchsummary` を用いてサマリを確認"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 256, 256]             864\n",
      "       BatchNorm2d-2         [-1, 32, 256, 256]              64\n",
      "              ReLU-3         [-1, 32, 256, 256]               0\n",
      "            Conv2d-4         [-1, 32, 256, 256]           9,216\n",
      "       BatchNorm2d-5         [-1, 32, 256, 256]              64\n",
      "              ReLU-6         [-1, 32, 256, 256]               0\n",
      "         MaxPool2d-7         [-1, 32, 128, 128]               0\n",
      "            Conv2d-8         [-1, 64, 128, 128]          18,432\n",
      "       BatchNorm2d-9         [-1, 64, 128, 128]             128\n",
      "             ReLU-10         [-1, 64, 128, 128]               0\n",
      "           Conv2d-11         [-1, 64, 128, 128]          36,864\n",
      "      BatchNorm2d-12         [-1, 64, 128, 128]             128\n",
      "             ReLU-13         [-1, 64, 128, 128]               0\n",
      "        MaxPool2d-14           [-1, 64, 64, 64]               0\n",
      "           Conv2d-15          [-1, 128, 64, 64]          73,728\n",
      "      BatchNorm2d-16          [-1, 128, 64, 64]             256\n",
      "             ReLU-17          [-1, 128, 64, 64]               0\n",
      "           Conv2d-18          [-1, 128, 64, 64]         147,456\n",
      "      BatchNorm2d-19          [-1, 128, 64, 64]             256\n",
      "             ReLU-20          [-1, 128, 64, 64]               0\n",
      "        MaxPool2d-21          [-1, 128, 32, 32]               0\n",
      "           Conv2d-22          [-1, 256, 32, 32]         294,912\n",
      "      BatchNorm2d-23          [-1, 256, 32, 32]             512\n",
      "             ReLU-24          [-1, 256, 32, 32]               0\n",
      "           Conv2d-25          [-1, 256, 32, 32]         589,824\n",
      "      BatchNorm2d-26          [-1, 256, 32, 32]             512\n",
      "             ReLU-27          [-1, 256, 32, 32]               0\n",
      "        MaxPool2d-28          [-1, 256, 16, 16]               0\n",
      "           Conv2d-29          [-1, 512, 16, 16]       1,179,648\n",
      "      BatchNorm2d-30          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-31          [-1, 512, 16, 16]               0\n",
      "           Conv2d-32          [-1, 512, 16, 16]       2,359,296\n",
      "      BatchNorm2d-33          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-34          [-1, 512, 16, 16]               0\n",
      "  ConvTranspose2d-35          [-1, 256, 32, 32]         524,544\n",
      "           Conv2d-36          [-1, 256, 32, 32]       1,179,648\n",
      "      BatchNorm2d-37          [-1, 256, 32, 32]             512\n",
      "             ReLU-38          [-1, 256, 32, 32]               0\n",
      "           Conv2d-39          [-1, 256, 32, 32]         589,824\n",
      "      BatchNorm2d-40          [-1, 256, 32, 32]             512\n",
      "             ReLU-41          [-1, 256, 32, 32]               0\n",
      "  ConvTranspose2d-42          [-1, 128, 64, 64]         131,200\n",
      "           Conv2d-43          [-1, 128, 64, 64]         294,912\n",
      "      BatchNorm2d-44          [-1, 128, 64, 64]             256\n",
      "             ReLU-45          [-1, 128, 64, 64]               0\n",
      "           Conv2d-46          [-1, 128, 64, 64]         147,456\n",
      "      BatchNorm2d-47          [-1, 128, 64, 64]             256\n",
      "             ReLU-48          [-1, 128, 64, 64]               0\n",
      "  ConvTranspose2d-49         [-1, 64, 128, 128]          32,832\n",
      "           Conv2d-50         [-1, 64, 128, 128]          73,728\n",
      "      BatchNorm2d-51         [-1, 64, 128, 128]             128\n",
      "             ReLU-52         [-1, 64, 128, 128]               0\n",
      "           Conv2d-53         [-1, 64, 128, 128]          36,864\n",
      "      BatchNorm2d-54         [-1, 64, 128, 128]             128\n",
      "             ReLU-55         [-1, 64, 128, 128]               0\n",
      "  ConvTranspose2d-56         [-1, 32, 256, 256]           8,224\n",
      "           Conv2d-57         [-1, 32, 256, 256]          18,432\n",
      "      BatchNorm2d-58         [-1, 32, 256, 256]              64\n",
      "             ReLU-59         [-1, 32, 256, 256]               0\n",
      "           Conv2d-60         [-1, 32, 256, 256]           9,216\n",
      "      BatchNorm2d-61         [-1, 32, 256, 256]              64\n",
      "             ReLU-62         [-1, 32, 256, 256]               0\n",
      "           Conv2d-63          [-1, 1, 256, 256]              33\n",
      "================================================================\n",
      "Total params: 7,763,041\n",
      "Trainable params: 7,763,041\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 404.00\n",
      "Params size (MB): 29.61\n",
      "Estimated Total Size (MB): 434.36\n",
      "----------------------------------------------------------------\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (3,256,256))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}